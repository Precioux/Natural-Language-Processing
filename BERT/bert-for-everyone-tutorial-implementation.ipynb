{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1471804,"sourceType":"datasetVersion","datasetId":863500}],"dockerImageVersionId":30097,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Import Required Libraries & Dataset","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport transformers\nfrom transformers import AutoModel, BertTokenizerFast\n\n# specify GPU\ndevice = torch.device(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:02:27.618596Z","iopub.execute_input":"2024-06-15T19:02:27.619003Z","iopub.status.idle":"2024-06-15T19:02:30.241187Z","shell.execute_reply.started":"2024-06-15T19:02:27.618890Z","shell.execute_reply":"2024-06-15T19:02:30.240447Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/spamdatatest/spamdata_v2.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:03:02.307264Z","iopub.execute_input":"2024-06-15T19:03:02.307766Z","iopub.status.idle":"2024-06-15T19:03:02.331267Z","shell.execute_reply.started":"2024-06-15T19:03:02.307726Z","shell.execute_reply":"2024-06-15T19:03:02.330271Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   label                                               text\n0      0  Go until jurong point, crazy.. Available only ...\n1      0                      Ok lar... Joking wif u oni...\n2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n3      0  U dun say so early hor... U c already then say...\n4      0  Nah I don't think he goes to usf, he lives aro...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The dataset consists of two columns – “label” and “text”. The column “text” contains the message body and the “label” is a binary variable where 1 means spam and 0 means the message is not a spam.","metadata":{}},{"cell_type":"code","source":"# check class distribution\ndf['label'].value_counts(normalize = True)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:03:55.322001Z","iopub.execute_input":"2024-06-15T19:03:55.322360Z","iopub.status.idle":"2024-06-15T19:03:55.344837Z","shell.execute_reply.started":"2024-06-15T19:03:55.322329Z","shell.execute_reply":"2024-06-15T19:03:55.343900Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"0    0.865937\n1    0.134063\nName: label, dtype: float64"},"metadata":{}}]},{"cell_type":"markdown","source":"### Split the Dataset into train / test","metadata":{}},{"cell_type":"code","source":"# split train dataset into train, validation and test sets\ntrain_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'], \n                                                                    random_state=2018, \n                                                                    test_size=0.3, \n                                                                    stratify=df['label'])\n\n\nval_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n                                                                random_state=2018, \n                                                                test_size=0.5, \n                                                                stratify=temp_labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:04:23.663802Z","iopub.execute_input":"2024-06-15T19:04:23.664088Z","iopub.status.idle":"2024-06-15T19:04:23.678984Z","shell.execute_reply.started":"2024-06-15T19:04:23.664039Z","shell.execute_reply":"2024-06-15T19:04:23.678135Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Import Bert - base- uncased","metadata":{}},{"cell_type":"code","source":"# import BERT-base pretrained model\nbert = AutoModel.from_pretrained('bert-base-uncased')\n\n# Load the BERT tokenizer\ntokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:05:18.224239Z","iopub.execute_input":"2024-06-15T19:05:18.224600Z","iopub.status.idle":"2024-06-15T19:05:33.223139Z","shell.execute_reply.started":"2024-06-15T19:05:18.224571Z","shell.execute_reply":"2024-06-15T19:05:33.222165Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"875c442b91984041a6ab8a2287604476"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e1f3f2cd0c240f086534616cb460eb0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daefca6a2ff549bd8c6d5f5aff5d0734"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"674dbb2c099e45649a022e110af11729"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fbf0bfe20aa432e8128fb4a173e9c4c"}},"metadata":{}}]},{"cell_type":"code","source":"# get length of all the messages in the train set\nseq_len = [len(i.split()) for i in train_text]\n\npd.Series(seq_len).hist(bins = 30)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:05:43.710858Z","iopub.execute_input":"2024-06-15T19:05:43.711197Z","iopub.status.idle":"2024-06-15T19:05:43.947506Z","shell.execute_reply.started":"2024-06-15T19:05:43.711168Z","shell.execute_reply":"2024-06-15T19:05:43.946662Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"### Tokenize & Encode the Sequences","metadata":{}},{"cell_type":"code","source":"# tokenize and encode sequences in the training set\ntokens_train = tokenizer.batch_encode_plus(\n    train_text.tolist(),\n    max_length = 25,\n    pad_to_max_length=True,\n    truncation=True\n)\n\n# tokenize and encode sequences in the validation set\ntokens_val = tokenizer.batch_encode_plus(\n    val_text.tolist(),\n    max_length = 25,\n    pad_to_max_length=True,\n    truncation=True\n)\n\n# tokenize and encode sequences in the test set\ntokens_test = tokenizer.batch_encode_plus(\n    test_text.tolist(),\n    max_length = 25,\n    pad_to_max_length=True,\n    truncation=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:06:40.515875Z","iopub.execute_input":"2024-06-15T19:06:40.516209Z","iopub.status.idle":"2024-06-15T19:06:40.882837Z","shell.execute_reply.started":"2024-06-15T19:06:40.516181Z","shell.execute_reply":"2024-06-15T19:06:40.882128Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### List to Tensors","metadata":{}},{"cell_type":"code","source":"## convert lists to tensors\n\ntrain_seq = torch.tensor(tokens_train['input_ids'])\ntrain_mask = torch.tensor(tokens_train['attention_mask'])\ntrain_y = torch.tensor(train_labels.tolist())\n\nval_seq = torch.tensor(tokens_val['input_ids'])\nval_mask = torch.tensor(tokens_val['attention_mask'])\nval_y = torch.tensor(val_labels.tolist())\n\ntest_seq = torch.tensor(tokens_test['input_ids'])\ntest_mask = torch.tensor(tokens_test['attention_mask'])\ntest_y = torch.tensor(test_labels.tolist())","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:07:04.622440Z","iopub.execute_input":"2024-06-15T19:07:04.622789Z","iopub.status.idle":"2024-06-15T19:07:04.665385Z","shell.execute_reply.started":"2024-06-15T19:07:04.622760Z","shell.execute_reply":"2024-06-15T19:07:04.664460Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_seq","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:13:58.121906Z","iopub.execute_input":"2024-06-15T19:13:58.122300Z","iopub.status.idle":"2024-06-15T19:13:58.136027Z","shell.execute_reply.started":"2024-06-15T19:13:58.122265Z","shell.execute_reply":"2024-06-15T19:13:58.135239Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"tensor([[  101,  2035,  2097,  ...,     0,     0,     0],\n        [  101,  2061,  1043,  ...,     0,     0,     0],\n        [  101,  2024,  2017,  ...,     0,     0,     0],\n        ...,\n        [  101, 24471,  4309,  ...,  5454,  2184,   102],\n        [  101,  8403,  5437,  ...,     0,     0,     0],\n        [  101, 20277,  4402,  ...,     0,     0,     0]])"},"metadata":{}}]},{"cell_type":"code","source":"train_mask","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:14:08.906572Z","iopub.execute_input":"2024-06-15T19:14:08.906891Z","iopub.status.idle":"2024-06-15T19:14:08.912943Z","shell.execute_reply.started":"2024-06-15T19:14:08.906864Z","shell.execute_reply":"2024-06-15T19:14:08.912134Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"tensor([[1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        ...,\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0]])"},"metadata":{}}]},{"cell_type":"code","source":"train_y","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:14:22.016339Z","iopub.execute_input":"2024-06-15T19:14:22.016681Z","iopub.status.idle":"2024-06-15T19:14:22.022096Z","shell.execute_reply.started":"2024-06-15T19:14:22.016653Z","shell.execute_reply":"2024-06-15T19:14:22.021270Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"tensor([0, 0, 0,  ..., 1, 0, 0])"},"metadata":{}}]},{"cell_type":"markdown","source":"### Data Loader","metadata":{}},{"cell_type":"code","source":"\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\n#define a batch size\nbatch_size = 32\n\n# wrap tensors\ntrain_data = TensorDataset(train_seq, train_mask, train_y)\n\n# sampler for sampling the data during training\ntrain_sampler = RandomSampler(train_data)\n\n# dataLoader for train set\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\n# wrap tensors\nval_data = TensorDataset(val_seq, val_mask, val_y)\n\n# sampler for sampling the data during training\nval_sampler = SequentialSampler(val_data)\n\n# dataLoader for validation set\nval_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:14:28.735064Z","iopub.execute_input":"2024-06-15T19:14:28.735392Z","iopub.status.idle":"2024-06-15T19:14:28.741415Z","shell.execute_reply.started":"2024-06-15T19:14:28.735363Z","shell.execute_reply":"2024-06-15T19:14:28.740407Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Model Architecture","metadata":{}},{"cell_type":"code","source":"# freeze all the parameters\nfor param in bert.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:14:44.139885Z","iopub.execute_input":"2024-06-15T19:14:44.140363Z","iopub.status.idle":"2024-06-15T19:14:44.147643Z","shell.execute_reply.started":"2024-06-15T19:14:44.140321Z","shell.execute_reply":"2024-06-15T19:14:44.146465Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class BERT_Arch(nn.Module):\n\n    def __init__(self, bert):\n        super(BERT_Arch, self).__init__()\n        \n        self.bert = bert \n        \n        # dropout layer\n        self.dropout = nn.Dropout(0.1)\n      \n        # relu activation function\n        self.relu =  nn.ReLU()\n\n        # dense layer 1\n        self.fc1 = nn.Linear(768,512)\n      \n        # dense layer 2 (Output layer)\n        self.fc2 = nn.Linear(512,2)\n\n        #softmax activation function\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    #define the forward pass\n    def forward(self, sent_id, mask):\n        \n        #pass the inputs to the model  \n        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n      \n        x = self.fc1(cls_hs)\n\n        x = self.relu(x)\n\n        x = self.dropout(x)\n\n        # output layer\n        x = self.fc2(x)\n      \n        # apply softmax activation\n        x = self.softmax(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:14:54.106376Z","iopub.execute_input":"2024-06-15T19:14:54.106714Z","iopub.status.idle":"2024-06-15T19:14:54.114744Z","shell.execute_reply.started":"2024-06-15T19:14:54.106685Z","shell.execute_reply":"2024-06-15T19:14:54.113842Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# pass the pre-trained BERT to our define architecture\nmodel = BERT_Arch(bert)\n\n# push the model to GPU\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:14:59.332670Z","iopub.execute_input":"2024-06-15T19:14:59.333005Z","iopub.status.idle":"2024-06-15T19:15:03.808175Z","shell.execute_reply.started":"2024-06-15T19:14:59.332975Z","shell.execute_reply":"2024-06-15T19:15:03.807394Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# optimizer from hugging face transformers\nfrom transformers import AdamW\n\n# define the optimizer\noptimizer = AdamW(model.parameters(),lr = 1e-5) ","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:21:00.836483Z","iopub.execute_input":"2024-06-15T19:21:00.836838Z","iopub.status.idle":"2024-06-15T19:21:00.845207Z","shell.execute_reply.started":"2024-06-15T19:21:00.836809Z","shell.execute_reply":"2024-06-15T19:21:00.844240Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\n\n#compute the class weights\nclass_weights = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n\nprint(\"Class Weights:\",class_weights)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:21:04.036464Z","iopub.execute_input":"2024-06-15T19:21:04.036804Z","iopub.status.idle":"2024-06-15T19:21:04.048702Z","shell.execute_reply.started":"2024-06-15T19:21:04.036776Z","shell.execute_reply":"2024-06-15T19:21:04.047806Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Class Weights: [0.57743559 3.72848948]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass classes=[0 1], y=1188    0\n5403    0\n2924    0\n880     1\n719     0\n       ..\n5121    0\n1006    1\n4374    1\n903     0\n5057    0\nName: label, Length: 3900, dtype: int64 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n  \"will result in an error\", FutureWarning)\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# converting list of class weights to a tensor\nweights= torch.tensor(class_weights,dtype=torch.float)\n\n# push to GPU\nweights = weights.to(device)\n\n# define the loss function\ncross_entropy  = nn.NLLLoss(weight=weights) \n\n# number of training epochs\nepochs = 10","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:21:15.915546Z","iopub.execute_input":"2024-06-15T19:21:15.915885Z","iopub.status.idle":"2024-06-15T19:21:17.333285Z","shell.execute_reply.started":"2024-06-15T19:21:15.915856Z","shell.execute_reply":"2024-06-15T19:21:17.332363Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### Finetune","metadata":{}},{"cell_type":"code","source":"# function to train the model\ndef train():\n    \n    model.train()\n    total_loss, total_accuracy = 0, 0\n  \n    # empty list to save model predictions\n    total_preds=[]\n  \n    # iterate over batches\n    for step,batch in enumerate(train_dataloader):\n        \n        # progress update after every 50 batches.\n        if step % 50 == 0 and not step == 0:\n            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n        \n        # push the batch to gpu\n        batch = [r.to(device) for r in batch]\n \n        sent_id, mask, labels = batch\n        \n        # clear previously calculated gradients \n        model.zero_grad()        \n\n        # get model predictions for the current batch\n        preds = model(sent_id, mask)\n\n        # compute the loss between actual and predicted values\n        loss = cross_entropy(preds, labels)\n\n        # add on to the total loss\n        total_loss = total_loss + loss.item()\n\n        # backward pass to calculate the gradients\n        loss.backward()\n\n        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        # update parameters\n        optimizer.step()\n\n        # model predictions are stored on GPU. So, push it to CPU\n        preds=preds.detach().cpu().numpy()\n\n    # append the model predictions\n    total_preds.append(preds)\n\n    # compute the training loss of the epoch\n    avg_loss = total_loss / len(train_dataloader)\n  \n      # predictions are in the form of (no. of batches, size of batch, no. of classes).\n      # reshape the predictions in form of (number of samples, no. of classes)\n    total_preds  = np.concatenate(total_preds, axis=0)\n\n    #returns the loss and predictions\n    return avg_loss, total_preds","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:21:54.245987Z","iopub.execute_input":"2024-06-15T19:21:54.246366Z","iopub.status.idle":"2024-06-15T19:21:54.256058Z","shell.execute_reply.started":"2024-06-15T19:21:54.246334Z","shell.execute_reply":"2024-06-15T19:21:54.255152Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# function for evaluating the model\ndef evaluate():\n    \n    print(\"\\nEvaluating...\")\n  \n    # deactivate dropout layers\n    model.eval()\n\n    total_loss, total_accuracy = 0, 0\n    \n    # empty list to save the model predictions\n    total_preds = []\n\n    # iterate over batches\n    for step,batch in enumerate(val_dataloader):\n        \n        # Progress update every 50 batches.\n        if step % 50 == 0 and not step == 0:\n            \n            # Calculate elapsed time in minutes.\n            elapsed = format_time(time.time() - t0)\n            \n            # Report progress.\n            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n\n        # push the batch to gpu\n        batch = [t.to(device) for t in batch]\n\n        sent_id, mask, labels = batch\n\n        # deactivate autograd\n        with torch.no_grad():\n            \n            # model predictions\n            preds = model(sent_id, mask)\n\n            # compute the validation loss between actual and predicted values\n            loss = cross_entropy(preds,labels)\n\n            total_loss = total_loss + loss.item()\n\n            preds = preds.detach().cpu().numpy()\n\n            total_preds.append(preds)\n\n    # compute the validation loss of the epoch\n    avg_loss = total_loss / len(val_dataloader) \n\n    # reshape the predictions in form of (number of samples, no. of classes)\n    total_preds  = np.concatenate(total_preds, axis=0)\n\n    return avg_loss, total_preds","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:22:01.337979Z","iopub.execute_input":"2024-06-15T19:22:01.338408Z","iopub.status.idle":"2024-06-15T19:22:01.347342Z","shell.execute_reply.started":"2024-06-15T19:22:01.338373Z","shell.execute_reply":"2024-06-15T19:22:01.346450Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# set initial loss to infinite\nbest_valid_loss = float('inf')\n\n# empty lists to store training and validation loss of each epoch\ntrain_losses=[]\nvalid_losses=[]\n\n#for each epoch\nfor epoch in range(epochs):\n     \n    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n    \n    #train model\n    train_loss, _ = train()\n    \n    #evaluate model\n    valid_loss, _ = evaluate()\n    \n    #save the best model\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), 'saved_weights.pt')\n    \n    # append training and validation loss\n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n    \n    print(f'\\nTraining Loss: {train_loss:.3f}')\n    print(f'Validation Loss: {valid_loss:.3f}')","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:22:05.634930Z","iopub.execute_input":"2024-06-15T19:22:05.635296Z","iopub.status.idle":"2024-06-15T19:23:18.168204Z","shell.execute_reply.started":"2024-06-15T19:22:05.635260Z","shell.execute_reply":"2024-06-15T19:23:18.167282Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"\n Epoch 1 / 10\n  Batch    50  of    122.\n  Batch   100  of    122.\n\nEvaluating...\n\nTraining Loss: 0.669\nValidation Loss: 0.646\n\n Epoch 2 / 10\n  Batch    50  of    122.\n  Batch   100  of    122.\n\nEvaluating...\n\nTraining Loss: 0.637\nValidation Loss: 0.616\n\n Epoch 3 / 10\n  Batch    50  of    122.\n  Batch   100  of    122.\n\nEvaluating...\n\nTraining Loss: 0.611\nValidation Loss: 0.586\n\n Epoch 4 / 10\n  Batch    50  of    122.\n  Batch   100  of    122.\n\nEvaluating...\n\nTraining Loss: 0.588\nValidation Loss: 0.560\n\n Epoch 5 / 10\n  Batch    50  of    122.\n  Batch   100  of    122.\n\nEvaluating...\n\nTraining Loss: 0.565\nValidation Loss: 0.543\n\n Epoch 6 / 10\n  Batch    50  of    122.\n  Batch   100  of    122.\n\nEvaluating...\n\nTraining Loss: 0.544\nValidation Loss: 0.522\n\n Epoch 7 / 10\n  Batch    50  of    122.\n  Batch   100  of    122.\n\nEvaluating...\n\nTraining Loss: 0.526\nValidation Loss: 0.497\n\n Epoch 8 / 10\n  Batch    50  of    122.\n  Batch   100  of    122.\n\nEvaluating...\n\nTraining Loss: 0.506\nValidation Loss: 0.477\n\n Epoch 9 / 10\n  Batch    50  of    122.\n  Batch   100  of    122.\n\nEvaluating...\n\nTraining Loss: 0.496\nValidation Loss: 0.462\n\n Epoch 10 / 10\n  Batch    50  of    122.\n  Batch   100  of    122.\n\nEvaluating...\n\nTraining Loss: 0.475\nValidation Loss: 0.444\n","output_type":"stream"}]},{"cell_type":"code","source":"#load weights of best model\npath = 'saved_weights.pt'\nmodel.load_state_dict(torch.load(path))","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:23:36.229640Z","iopub.execute_input":"2024-06-15T19:23:36.229979Z","iopub.status.idle":"2024-06-15T19:23:36.541006Z","shell.execute_reply.started":"2024-06-15T19:23:36.229950Z","shell.execute_reply":"2024-06-15T19:23:36.540126Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Predictions","metadata":{}},{"cell_type":"code","source":"# get predictions for test data\nwith torch.no_grad():\n    preds = model(test_seq.to(device), test_mask.to(device))\n    preds = preds.detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:23:52.117589Z","iopub.execute_input":"2024-06-15T19:23:52.117938Z","iopub.status.idle":"2024-06-15T19:23:52.707884Z","shell.execute_reply.started":"2024-06-15T19:23:52.117909Z","shell.execute_reply":"2024-06-15T19:23:52.707142Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# model's performance\npreds = np.argmax(preds, axis = 1)\nprint(classification_report(test_y, preds))","metadata":{"execution":{"iopub.status.busy":"2024-06-15T19:23:58.119664Z","iopub.execute_input":"2024-06-15T19:23:58.120006Z","iopub.status.idle":"2024-06-15T19:23:58.131788Z","shell.execute_reply.started":"2024-06-15T19:23:58.119974Z","shell.execute_reply":"2024-06-15T19:23:58.130933Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.97      0.86      0.91       724\n           1       0.47      0.83      0.60       112\n\n    accuracy                           0.85       836\n   macro avg       0.72      0.84      0.76       836\nweighted avg       0.90      0.85      0.87       836\n\n","output_type":"stream"}]}]}